{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Network \n",
    "\n",
    "\n",
    "\n",
    "## What inspired Convolutional Networks?\n",
    "\n",
    "CNNs are biologically-inspired models inspired by research by D. H. Hubel and T. N. Wiesel. They proposed an explanation for the way in which mammals visually perceive the world around them using a layered architecture of neurons in the brain, and this in turn inspired engineers to attempt to develop similar pattern recognition mechanisms in computer vision.\n",
    "\n",
    "In their hypothesis, within the visual cortex, complex functional responses generated by \"complex cells\" are constructed from more simplistic responses from \"simple cells'. \n",
    "\n",
    "The architecture of deep convolutional neural networks was inspired by the ideas mentioned above \n",
    "- local connections \n",
    "- layering  \n",
    "- spatial invariance (shifting the input signal results in an equally shifted output signal. , most of us are able to recognize specific faces under a variety of conditions because we learn abstraction These abstractions are thus invariant to size, contrast, rotation, orientation\n",
    " \n",
    "However, it remains to be seen if these computational mechanisms of convolutional neural networks are similar to the computation mechanisms occurring in the primate visual system\n",
    "\n",
    "- convolution operation\n",
    "- shared weights\n",
    "- pooling/subsampling \n",
    "\n",
    "## How does it work? \n",
    "\n",
    "![alt text](../images/slide1_img1.jpg \"Logo Title Text 1\")\n",
    "![alt text](../images/slide1_img2.jpg \"Logo Title Text 1\")\n",
    "\n",
    "### Step 1 - Prepare a dataset of images\n",
    "\n",
    "![alt text](../images/slide1_img3.png \"Logo Title Text 1\")\n",
    "\n",
    "- Every image is a matrix of pixel values. \n",
    "- The range of values that can be encoded in each pixel depends upon its bit size. \n",
    "- Most commonly, we have 8 bit or 1 Byte-sized pixels. Thus the possible range of values a single pixel can represent is [0, 255]. \n",
    "\n",
    "### Step 2 - Convolution \n",
    "\n",
    "![alt text](../images/slide1_Convolution_schematic.gif \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](../images/slide1_img4.png \"Logo Title Text 1\")\n",
    "\n",
    "- A convolution is an orderly procedure where two sources of information are intertwined.\n",
    "\n",
    "- A kernel (also called a filter) is a smaller-sized matrix in comparison to the input dimensions of the image, that consists of real valued entries.\n",
    "\n",
    "- Kernels are then convolved with the input volume to obtain so-called ‘activation maps’ (also called feature maps).  \n",
    "- Activation maps indicate ‘activated’ regions, i.e. regions where features specific to the kernel have been detected in the input. \n",
    "\n",
    "- The real values of the kernel matrix change with each learning iteration over the training set, indicating that the network is learning to identify which regions are of significance for extracting features from the data.\n",
    "\n",
    "- We compute the dot product between the kernel and the input matrix. -The convolved value obtained by summing the resultant terms from the dot product forms a single entry in the activation matrix. \n",
    "\n",
    "- The patch selection is then slided (towards the right, or downwards when the boundary of the matrix is reached) by a certain amount called the ‘stride’ value, and the process is repeated till the entire input image has been processed. - The process is carried out for all colour channels.\n",
    "\n",
    "- instead of connecting each neuron to all possible pixels, we specify a 2 dimensional region called the ‘receptive field[14]’ (say of size 5×5 units) extending to the entire depth of the input (5x5x3 for a 3 colour channel input), within which the encompassed pixels are fully connected to the neural network’s input layer. It’s over these small regions that the network layer cross-sections (each consisting of several neurons (called ‘depth columns’)) operate and produce the activation map. (reduces computational complexity)\n",
    "\n",
    "\n",
    "###  Step 3 - Pooling\n",
    "![alt text](../images/slide1_img5.png \"Logo Title Text 1\")\n",
    "\n",
    "- Pooling reducing the spatial dimensions (Width x Height) of the Input Volume for the next Convolutional Layer. It does not affect the depth dimension of the Volume.  \n",
    "- The transformation is either performed by taking the maximum value from the values observable in the window (called ‘max pooling’), or by taking the average of the values. Max pooling has been favoured over others due to its better performance characteristics.\n",
    "- also called downsampling\n",
    "\n",
    "###  Step 4 - Normalization (ReLU in our case)\n",
    "\n",
    "![alt text](../images/slide1_normrelu.png \"Logo Title Text 1\")\n",
    "\n",
    "Normalization (keep the math from breaking by turning all negative numbers to 0)  (`RELU`) a stack of images becomes a stack of images with no negative values. \n",
    "\n",
    "We can use batch normalization if we use other type of activation functions like `tanh` for example\n",
    "\n",
    "### Step 5 - Regularization \n",
    "\n",
    "- Dropout forces an artificial neural network to learn multiple independent representations of the same data by alternately randomly disabling neurons in the learning phase.\n",
    "- Dropout is a vital feature in almost every state-of-the-art neural network implementation.\n",
    "- To perform dropout on a layer, you randomly set some of the layer's values to 0 during forward propagation.\n",
    "\n",
    "![alt text](../images/slide1_img6.png \"Logo Title Text 1\")\n",
    "\n",
    "###  Step 6 - Probability Conversion\n",
    "\n",
    "At the very end of our network (the tail), we'll apply a softmax function to convert the outputs to probability values for each class. \n",
    "\n",
    "![alt text](../images/slide1_img7.JPG \"Logo Title Text 1\")\n",
    "\n",
    "\n",
    "###  Step 7 - Choose most likely label (max probability value) \n",
    "\n",
    "argmax(softmax_outputs)\n",
    "\n",
    "These 7 steps are one forward pass through the network.\n",
    "\n",
    "## So how do we learn the magic numbers? \n",
    "\n",
    "- We can learn features and weight values through backpropagation\n",
    "\n",
    "![alt text](../images/slide1_img11.png \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](../images/slide1_img8.png \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](../images/slide1_img10.jpg \"Logo Title Text 1\")\n",
    "\n",
    "The other hyperparameters are set by humans and they are an active field of research (finding the optimal ones)\n",
    "\n",
    "i.e -  number of neurons, number of features, size of features, poooling window size, window stride\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ower CNN Model\n",
    "\n",
    "\n",
    "![alt text](../images/model.jpg \"Ower model\")\n",
    "\n",
    "### Input Image in gray-scale (128 x 128 x 1)\n",
    "We choose a little size to reduce the cost of computation.\n",
    "<img src=\"../images/original_image.png\" width=\"200\">\n",
    "\n",
    "### High-pass Filter (5 x5 )\n",
    "We choose a little size to reduce the cost of computation.\n",
    "$$\n",
    "\\left(\\begin{array}{cc} \n",
    "-1 &  2 &  -2 &  2 & -1\\\\\n",
    "2 & -6 &   8 & -6 &  2\\\\\n",
    "-2 &  8 & -12 &  8 & -2\\\\\n",
    "2 & -6 & 8 & -6 & 2\\\\\n",
    "-1 &  2 &  -2 &  2 & -1\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "<img src=\"../images/hpf_filter.png\" width=\"250\">\n",
    "<img src=\"../images/hpf_image.png\" width=\"200\">\n",
    "[Resemblance between cover and stego after fitring](https://huddle.github.io/Resemble.js/)\n",
    "### First conv layer\n",
    "#### Conv Layer 1 Weights (3x3x32)\n",
    "<img src=\"../images/weigts_conv1.png\">\n",
    "#### Conv layer 1 outputs (128x128x32) (using Zero padding)\n",
    "<img src=\"../images/images_conv1.png\">\n",
    "#### Max pooling \n",
    "kernel size (2x2) ===>  output(64x64x32)\n",
    "#### Conv Layer 2 Weights (3x3x32)\n",
    "<img src=\"../images/weigts_conv2.png\">\n",
    "#### Conv layer 2 outputs (32x32x32) (using Zero padding)\n",
    "<img src=\"../images/images_conv2.png\">\n",
    "#### Max pooling \n",
    "kernel size (2x2) ===>  output(32x32x32)\n",
    "#### Conv Layer 3 Weights (3x3x64)\n",
    "<img src=\"../images/weigts_conv3.png\">\n",
    "#### Conv layer 2 outputs (32x32x64) (using Zero padding)\n",
    "<img src=\"../images/images_conv3.png\">\n",
    "#### Max pooling \n",
    "kernel size (2x2) ===>  output(16x16x64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
