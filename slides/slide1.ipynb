{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network architectures\n",
    "\n",
    "![alt text](../images/slide1_img0.png \"Neural Networks\")\n",
    "\n",
    "\n",
    "# Convolutional Network \n",
    "\n",
    "\n",
    "\n",
    "## What inspired Convolutional Networks?\n",
    "\n",
    "CNNs are biologically-inspired models inspired by research by D. H. Hubel and T. N. Wiesel. They proposed an explanation for the way in which mammals visually perceive the world around them using a layered architecture of neurons in the brain, and this in turn inspired engineers to attempt to develop similar pattern recognition mechanisms in computer vision.\n",
    "\n",
    "In their hypothesis, within the visual cortex, complex functional responses generated by \"complex cells\" are constructed from more simplistic responses from \"simple cells'. \n",
    "\n",
    "The architecture of deep convolutional neural networks was inspired by the ideas mentioned above \n",
    "- local connections \n",
    "- layering  \n",
    "- spatial invariance (shifting the input signal results in an equally shifted output signal. , most of us are able to recognize specific faces under a variety of conditions because we learn abstraction These abstractions are thus invariant to size, contrast, rotation, orientation\n",
    " \n",
    "However, it remains to be seen if these computational mechanisms of convolutional neural networks are similar to the computation mechanisms occurring in the primate visual system\n",
    "\n",
    "- convolution operation\n",
    "- shared weights\n",
    "- pooling/subsampling \n",
    "\n",
    "![alt text](../images/slide1_img_layers.png \"Logo Title Text 1\")\n",
    "\n",
    "## How does it work? \n",
    "\n",
    "![alt text](../images/slide1_img1.jpg \"Logo Title Text 1\")\n",
    "![alt text](../images/slide1_img2.jpg \"Logo Title Text 1\")\n",
    "\n",
    "### Step 1 - Prepare a dataset of images\n",
    "\n",
    "![alt text](../images/slide1_img3.png \"Logo Title Text 1\")\n",
    "\n",
    "- Every image is a matrix of pixel values. \n",
    "- The range of values that can be encoded in each pixel depends upon its bit size. \n",
    "- Most commonly, we have 8 bit or 1 Byte-sized pixels. Thus the possible range of values a single pixel can represent is [0, 255]. \n",
    "\n",
    "### Step 2 - Convolution \n",
    "\n",
    "![alt text](../images/slide1_Convolution_schematic.gif \"Logo Title Text 1\")\n",
    "\n",
    "\n",
    "\n",
    "- A convolution is an orderly procedure where two sources of information are intertwined.\n",
    "\n",
    "- A kernel (also called a filter) is a smaller-sized matrix in comparison to the input dimensions of the image, that consists of real valued entries.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###  Step 3 - Activation function (ReLU in our case)\n",
    "\n",
    "- Kernels are then convolved with the input volume to obtain so-called ‘activation maps’ (also called feature maps).  \n",
    "- Activation maps indicate ‘activated’ regions, i.e. regions where features specific to the kernel have been detected in the input. \n",
    "\n",
    "![alt text](../images/slide1_activation_fn2.png \"Other activation functions\")\n",
    "![alt text](../images/slide1_activation_fn.png \"Other activation functions\")\n",
    "\n",
    "\n",
    "\n",
    "###  Step 4 - Pooling\n",
    "![alt text](../images/slide1_img5.png \"Logo Title Text 1\")\n",
    "\n",
    "- Pooling reducing the spatial dimensions (Width x Height) of the Input Volume for the next Convolutional Layer. It does not affect the depth dimension of the Volume.  \n",
    "- The transformation is either performed by taking the maximum value from the values observable in the window (called ‘max pooling’), or by taking the average of the values. Max pooling has been favoured over others due to its better performance characteristics.\n",
    "- also called downsampling\n",
    "\n",
    "### Step 5 - Regularization \n",
    "\n",
    "- Dropout forces an artificial neural network to learn multiple independent representations of the same data by alternately randomly disabling neurons in the learning phase.\n",
    "- Dropout is a vital feature in almost every state-of-the-art neural network implementation.\n",
    "- To perform dropout on a layer, you randomly set some of the layer's values to 0 during forward propagation.\n",
    "\n",
    "![alt text](../images/slide1_img6.png \"Logo Title Text 1\")\n",
    "\n",
    "###  Step 6 - Probability Conversion\n",
    "\n",
    "At the very end of our network (the tail), we'll apply a softmax function to convert the outputs to probability values for each class. \n",
    "\n",
    "![alt text](../images/slide1_img7.JPG \"Logo Title Text 1\")\n",
    "\n",
    "\n",
    "###  Step 7 - Choose most likely label (max probability value) \n",
    "\n",
    "argmax(softmax_outputs)\n",
    "\n",
    "These 7 steps are one forward pass through the network.\n",
    "\n",
    "## So how do we learn the magic numbers? \n",
    "\n",
    "- We can learn features and weight values through backpropagation\n",
    "\n",
    "![alt text](../images/slide1_img11.png \"Geoffrey Hinton\")\n",
    "\n",
    "![alt text](../images/slide1_img8.png \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](../images/slide1_img10.jpg \"Logo Title Text 1\")\n",
    "\n",
    "The other hyperparameters are set by humans and they are an active field of research (finding the optimal ones)\n",
    "\n",
    "i.e -  number of neurons, number of features, size of features, poooling window size, window stride\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ower CNN Model\n",
    "\n",
    "\n",
    "![alt text](../images/model.png \"Ower model\")\n",
    "\n",
    "### Convolutional layer\n",
    "\n",
    "![alt text](../images/weigts_conv05.png \"Ower model\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used technologies\n",
    "\n",
    "- TensorFlow\n",
    "- Keras\n",
    "- sickit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
